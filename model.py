import torch
import torch.nn as nn
from torchvision import models

"""
 Channel Attention
"""
class ChannelAttention(nn.Module):
    def __init__(self):
        super(ChannelAttention, self).__init__()
        self.maximum_pool = nn.AdaptiveMaxPool2d(1)
        self.average_pool = nn.AdaptiveAvgPool2d(1)

        self.conv1   = nn.Conv2d(64, 4, 1, bias=False)
        self.relu = nn.ReLU()
        self.conv2   = nn.Conv2d(4, 64, 1, bias=False)

        #init weight
        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')
        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_out', nonlinearity='relu')

    def forward(self, input):
        maximum_output = self.conv2(self.relu(self.conv1(self.maximum_pool(input))))
        average_output = self.conv2(self.relu(self.conv1(self.average_pool(input))))
        output = average_output + maximum_output
        return nn.Sigmoid(output)

"""
 Spatial Attention
"""
class SpatialAttention(nn.Module):
    def __init__(self):
        super(SpatialAttention, self).__init__()
        self.conv1 = nn.Conv2d(2, 1, 5, padding=1, bias=False)

        # init weight
        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')
    def forward(self, input):
        maximum_output, _ = torch.max(input, dim=1, keepdim=True)
        average_output = torch.mean(input, dim=1, keepdim=True)
        concat_feature = torch.cat([average_output, maximum_output], dim=1)
        output = self.conv1(concat_feature)
        return nn.Sigmoid(output)

class Network(nn.Module):
    def __init__(self,use_attention=False,modify_network=False):
        super(Network,self).__init__()
        # bool flag for use attention or not
        self.use_attention = use_attention
        # bool flag for  modify network or not
        self.modify_network = modify_network

        # base model
        self.model_finetune = models.resnet18(pretrained=False)
        # add attention
        if self.use_attention:
            self._add_attention()
        # modify downsample layer in shortcut
        if self.modify_network:
            self._modify_network()

        # fc layer
        self.feature_nums = self.model_finetune.fc.in_features
        self.model_finetune.fc = nn.Sequential(
            nn.Dropout(0.2),
            nn.Linear(self.feature_nums, 9))
        # weight and bias init
        nn.init.constant_(self.model_finetune.fc[1].weight, 1)
        nn.init.constant_(self.model_finetune.fc[1].bias, 0)

    def _add_attention(self):
        self.ca = ChannelAttention()
        self.sa = SpatialAttention()

    def _modify_network(self):
        # change the downsample of the shortcut in layer2,layer3,layer4
        self.model_finetune.layer2[0].downsample = self._make_downsample(64, 128)
        self.model_finetune.layer3[0].downsample = self._make_downsample(128, 256)
        self.model_finetune.layer4[0].downsample = self._make_downsample(256, 512)

    def _make_downsample(self,in_planes,out_planes):
        # use AvgPool2d to downsample instead of Conv2d(stride=2)
        downsample = nn.Sequential(
            nn.AvgPool2d(kernel_size=2, stride=2),
            nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, bias=False),
            nn.BatchNorm2d(out_planes),
        )
        # weight and bias init
        # reference to torchvision.models.resnet18
        for operator in downsample:
            if isinstance(operator, nn.Conv2d):
                nn.init.kaiming_normal_(operator.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(operator, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(operator.weight, 1)
                nn.init.constant_(operator.bias, 0)
        return downsample

    def forward(self, input):
        #Shallow Convolution
        #two times downsampling
        input = self.model_finetune.conv1(input)
        input = self.model_finetune.bn1(input)
        conv1_output = self.model_finetune.relu(input)

        if self.use_attention:
            conv1_output = self.ca(conv1_output) * conv1_output
            conv1_output = self.sa(conv1_output) * conv1_output

        maxpool_output = self.model_finetune.maxpool(conv1_output)

        # sixteen times downsampling
        layer1_output = self.model_finetune.layer1(maxpool_output)
        layer2_output = self.model_finetune.layer2(layer1_output)
        layer3_output = self.model_finetune.layer3(layer2_output)
        layer4_output = self.model_finetune.layer4(layer3_output)

        # use AdaptiveAvgPool2d to global pooling
        avg_output = self.model_finetune.avgpool(layer4_output)

        # Full connection layer output
        fc_input = avg_output.reshape(avg_output.size(0), -1)
        cls_output = self.model_finetune.fc(fc_input)
        return cls_output